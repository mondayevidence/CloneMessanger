{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the kernel depth must be same as the receptive depth and input depth cos\n",
    "# we do an element wise multiplication on the matrix followed by a summation\n",
    "# yielding a single number (feature map)\n",
    "# sliding/convolving the kernel pnce across the image produces one feature map\n",
    "# continuing producing as many feture maps as possible\n",
    "# more kernels = more feature map channels\n",
    "\n",
    "# Pooling/Downsampling simply reduces the feature map size to what we like\n",
    "# Max pooling is taking the maximumm number out of the feature map\n",
    "# Average pooling is taking the average from the feature map and downsampled number becomes the average\n",
    "\n",
    "# valid padding - Zero padding\n",
    "# Every time you do not pad your image, you will always have a small output size\n",
    "# Same padding - non-zero padding; done to make sure our output size is same as input size\n",
    "# by padding a bunch of zeros around\n",
    "\n",
    "# how to calculate the matrix size we want for padding:\n",
    "# O = [(W-K+2P)/S] + 1\n",
    "# O: output height/length, W: input height/length\n",
    "# K: filter size (kernel size), P: padding, S: stride\n",
    "# P = (k-1)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#Loading dataset\n",
    "train_dataset =dsets.MNIST(root='./data',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                          train=False,\n",
    "                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monda\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monda\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monda\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monda\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset iterable\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We  need to calculate our expected output given an input size on 28;\n",
    "# from train and test dataset and we are using 1 stride\n",
    "\n",
    "# here, we are using kernel size =5; for convolution \n",
    "# non zero padding P=(k-1)/2\n",
    "# P = (5-1)/2 = 2\n",
    "# stride = 1\n",
    "# remember: O = [(W-K+2P)/S] + 1; for convolution\n",
    "# O = W/K; for pooling...here we can choose filter size of 2; k =2\n",
    "\n",
    "# so for the 1st convolution; O = [(28-5+2(2))/1] + 1 = 28\n",
    "# so for 1st max pooling: O = W/K = 28/2 = 14\n",
    "\n",
    "# convolution 2; O = [(14-5+2(2))/1] + 1 = 14\n",
    "# max pooling 2; O = W/K = 14/2 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model class\n",
    "# in_channels = 1 because we are using MNIST image; which is just a single grayscale color\n",
    "# out_channels = 16; the number of kernels we choose; one unique kernel produces\n",
    "# one feature map, so here we have 16 feature map\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU() # after every convoluntional layer, we need to pass through a non linearity & ReLU is the best\n",
    "        \n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)  # to reduce the image size\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)  # 16 feature maps fed into the in_channel from conv1\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 10)   # ouput dimension is always 10; input_dim from the outpu channel on conv2 and the maxpool 2 dimension calculated in the above cell\n",
    "        \n",
    "        def forward(self, x):\n",
    "            # Covoluntion 1\n",
    "            out = self.cnn1(x)\n",
    "            out = self.relu1(out)\n",
    "            \n",
    "            # Max pool 1\n",
    "            out = self.maxpool1(out)\n",
    "            \n",
    "            # Convolution 2\n",
    "            out = self.cnn2(out)\n",
    "            out = self.relu2(out)\n",
    "            \n",
    "            # Max pool 2\n",
    "            out = self.maxpool2(out)\n",
    "            \n",
    "            # Resize\n",
    "            # Original size: (100, 32, 7, 7) 100, because of batch_size; input 32, 7, 7\n",
    "            # out.size(0): 100\n",
    "            # New out size: (100, 32*7*7)\n",
    "            out = out.view(out.size(0), -1)  # -1 means reshape to the remaining values: 32*7*7\n",
    "            \n",
    "            # Linear function (readout)\n",
    "            out = self.fc1(out)\n",
    "            \n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model Class\n",
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate loss class\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Optimizer Class\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
